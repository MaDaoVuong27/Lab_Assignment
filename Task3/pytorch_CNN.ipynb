{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7846f6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad7e10d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "num_epochs = 20\n",
    "batch_size = 4\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51edb3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a23dc64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d7e21ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5373, -0.6627, -0.6078,  ...,  0.2392,  0.1922,  0.1608],\n",
      "         [-0.8745, -1.0000, -0.8588,  ..., -0.0353, -0.0667, -0.0431],\n",
      "         [-0.8039, -0.8745, -0.6157,  ..., -0.0745, -0.0588, -0.1451],\n",
      "         ...,\n",
      "         [ 0.6314,  0.5765,  0.5529,  ...,  0.2549, -0.5608, -0.5843],\n",
      "         [ 0.4118,  0.3569,  0.4588,  ...,  0.4431, -0.2392, -0.3490],\n",
      "         [ 0.3882,  0.3176,  0.4039,  ...,  0.6941,  0.1843, -0.0353]],\n",
      "\n",
      "        [[-0.5137, -0.6392, -0.6235,  ...,  0.0353, -0.0196, -0.0275],\n",
      "         [-0.8431, -1.0000, -0.9373,  ..., -0.3098, -0.3490, -0.3176],\n",
      "         [-0.8118, -0.9451, -0.7882,  ..., -0.3412, -0.3412, -0.4275],\n",
      "         ...,\n",
      "         [ 0.3333,  0.2000,  0.2627,  ...,  0.0431, -0.7569, -0.7333],\n",
      "         [ 0.0902, -0.0353,  0.1294,  ...,  0.1608, -0.5137, -0.5843],\n",
      "         [ 0.1294,  0.0118,  0.1137,  ...,  0.4431, -0.0745, -0.2784]],\n",
      "\n",
      "        [[-0.5059, -0.6471, -0.6627,  ..., -0.1529, -0.2000, -0.1922],\n",
      "         [-0.8431, -1.0000, -1.0000,  ..., -0.5686, -0.6078, -0.5529],\n",
      "         [-0.8353, -1.0000, -0.9373,  ..., -0.6078, -0.6078, -0.6706],\n",
      "         ...,\n",
      "         [-0.2471, -0.7333, -0.7961,  ..., -0.4510, -0.9451, -0.8431],\n",
      "         [-0.2471, -0.6706, -0.7647,  ..., -0.2627, -0.7333, -0.7333],\n",
      "         [-0.0902, -0.2627, -0.3176,  ...,  0.0980, -0.3412, -0.4353]]]) 6\n",
      "torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "first = train_set[0]\n",
    "features, labels = first\n",
    "print(features, labels)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01b9eb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader)) #iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1f3818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23c59c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) # Input channels = 3 (RGB), Output channels (The number of filter) = 6, Filter (Kernel) size = 5\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae1155aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f52dbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [1000/12500], Loss: 1.8185\n",
      "Epoch [1/20], Step [2000/12500], Loss: 2.1187\n",
      "Epoch [1/20], Step [3000/12500], Loss: 0.9019\n",
      "Epoch [1/20], Step [4000/12500], Loss: 1.5808\n",
      "Epoch [1/20], Step [5000/12500], Loss: 1.6466\n",
      "Epoch [1/20], Step [6000/12500], Loss: 0.7833\n",
      "Epoch [1/20], Step [7000/12500], Loss: 1.4117\n",
      "Epoch [1/20], Step [8000/12500], Loss: 1.0462\n",
      "Epoch [1/20], Step [9000/12500], Loss: 1.6253\n",
      "Epoch [1/20], Step [10000/12500], Loss: 1.0920\n",
      "Epoch [1/20], Step [11000/12500], Loss: 1.5629\n",
      "Epoch [1/20], Step [12000/12500], Loss: 2.2404\n",
      "Epoch [2/20], Step [1000/12500], Loss: 1.5357\n",
      "Epoch [2/20], Step [2000/12500], Loss: 0.5176\n",
      "Epoch [2/20], Step [3000/12500], Loss: 0.5640\n",
      "Epoch [2/20], Step [4000/12500], Loss: 1.5422\n",
      "Epoch [2/20], Step [5000/12500], Loss: 1.3612\n",
      "Epoch [2/20], Step [6000/12500], Loss: 0.9270\n",
      "Epoch [2/20], Step [7000/12500], Loss: 0.8482\n",
      "Epoch [2/20], Step [8000/12500], Loss: 0.7749\n",
      "Epoch [2/20], Step [9000/12500], Loss: 0.9152\n",
      "Epoch [2/20], Step [10000/12500], Loss: 0.8533\n",
      "Epoch [2/20], Step [11000/12500], Loss: 1.3805\n",
      "Epoch [2/20], Step [12000/12500], Loss: 0.9226\n",
      "Epoch [3/20], Step [1000/12500], Loss: 1.3513\n",
      "Epoch [3/20], Step [2000/12500], Loss: 1.3421\n",
      "Epoch [3/20], Step [3000/12500], Loss: 1.3289\n",
      "Epoch [3/20], Step [4000/12500], Loss: 0.4235\n",
      "Epoch [3/20], Step [5000/12500], Loss: 1.9642\n",
      "Epoch [3/20], Step [6000/12500], Loss: 2.4402\n",
      "Epoch [3/20], Step [7000/12500], Loss: 0.9726\n",
      "Epoch [3/20], Step [8000/12500], Loss: 1.7836\n",
      "Epoch [3/20], Step [9000/12500], Loss: 2.8460\n",
      "Epoch [3/20], Step [10000/12500], Loss: 0.8834\n",
      "Epoch [3/20], Step [11000/12500], Loss: 0.5895\n",
      "Epoch [3/20], Step [12000/12500], Loss: 1.9544\n",
      "Epoch [4/20], Step [1000/12500], Loss: 1.0432\n",
      "Epoch [4/20], Step [2000/12500], Loss: 1.0945\n",
      "Epoch [4/20], Step [3000/12500], Loss: 0.9881\n",
      "Epoch [4/20], Step [4000/12500], Loss: 1.4333\n",
      "Epoch [4/20], Step [5000/12500], Loss: 0.8295\n",
      "Epoch [4/20], Step [6000/12500], Loss: 0.5871\n",
      "Epoch [4/20], Step [7000/12500], Loss: 1.0804\n",
      "Epoch [4/20], Step [8000/12500], Loss: 1.7235\n",
      "Epoch [4/20], Step [9000/12500], Loss: 1.1414\n",
      "Epoch [4/20], Step [10000/12500], Loss: 1.8120\n",
      "Epoch [4/20], Step [11000/12500], Loss: 0.4364\n",
      "Epoch [4/20], Step [12000/12500], Loss: 1.7270\n",
      "Epoch [5/20], Step [1000/12500], Loss: 1.7357\n",
      "Epoch [5/20], Step [2000/12500], Loss: 3.0907\n",
      "Epoch [5/20], Step [3000/12500], Loss: 0.6207\n",
      "Epoch [5/20], Step [4000/12500], Loss: 1.0222\n",
      "Epoch [5/20], Step [5000/12500], Loss: 0.3270\n",
      "Epoch [5/20], Step [6000/12500], Loss: 1.7485\n",
      "Epoch [5/20], Step [7000/12500], Loss: 1.3028\n",
      "Epoch [5/20], Step [8000/12500], Loss: 1.6223\n",
      "Epoch [5/20], Step [9000/12500], Loss: 1.1798\n",
      "Epoch [5/20], Step [10000/12500], Loss: 1.3413\n",
      "Epoch [5/20], Step [11000/12500], Loss: 0.2656\n",
      "Epoch [5/20], Step [12000/12500], Loss: 1.0888\n",
      "Epoch [6/20], Step [1000/12500], Loss: 0.4959\n",
      "Epoch [6/20], Step [2000/12500], Loss: 1.5398\n",
      "Epoch [6/20], Step [3000/12500], Loss: 1.3601\n",
      "Epoch [6/20], Step [4000/12500], Loss: 0.3052\n",
      "Epoch [6/20], Step [5000/12500], Loss: 1.3105\n",
      "Epoch [6/20], Step [6000/12500], Loss: 1.2154\n",
      "Epoch [6/20], Step [7000/12500], Loss: 3.4667\n",
      "Epoch [6/20], Step [8000/12500], Loss: 1.1938\n",
      "Epoch [6/20], Step [9000/12500], Loss: 2.1376\n",
      "Epoch [6/20], Step [10000/12500], Loss: 0.7389\n",
      "Epoch [6/20], Step [11000/12500], Loss: 0.8861\n",
      "Epoch [6/20], Step [12000/12500], Loss: 1.3362\n",
      "Epoch [7/20], Step [1000/12500], Loss: 0.8562\n",
      "Epoch [7/20], Step [2000/12500], Loss: 0.8483\n",
      "Epoch [7/20], Step [3000/12500], Loss: 0.4292\n",
      "Epoch [7/20], Step [4000/12500], Loss: 0.3291\n",
      "Epoch [7/20], Step [5000/12500], Loss: 0.9159\n",
      "Epoch [7/20], Step [6000/12500], Loss: 0.8038\n",
      "Epoch [7/20], Step [7000/12500], Loss: 0.6010\n",
      "Epoch [7/20], Step [8000/12500], Loss: 1.1682\n",
      "Epoch [7/20], Step [9000/12500], Loss: 0.3060\n",
      "Epoch [7/20], Step [10000/12500], Loss: 1.3541\n",
      "Epoch [7/20], Step [11000/12500], Loss: 1.0058\n",
      "Epoch [7/20], Step [12000/12500], Loss: 0.5284\n",
      "Epoch [8/20], Step [1000/12500], Loss: 1.1421\n",
      "Epoch [8/20], Step [2000/12500], Loss: 2.4283\n",
      "Epoch [8/20], Step [3000/12500], Loss: 0.5795\n",
      "Epoch [8/20], Step [4000/12500], Loss: 0.4862\n",
      "Epoch [8/20], Step [5000/12500], Loss: 0.6105\n",
      "Epoch [8/20], Step [6000/12500], Loss: 0.7964\n",
      "Epoch [8/20], Step [7000/12500], Loss: 0.5886\n",
      "Epoch [8/20], Step [8000/12500], Loss: 1.0872\n",
      "Epoch [8/20], Step [9000/12500], Loss: 0.7039\n",
      "Epoch [8/20], Step [10000/12500], Loss: 1.4305\n",
      "Epoch [8/20], Step [11000/12500], Loss: 0.9064\n",
      "Epoch [8/20], Step [12000/12500], Loss: 0.8116\n",
      "Epoch [9/20], Step [1000/12500], Loss: 0.5822\n",
      "Epoch [9/20], Step [2000/12500], Loss: 0.0783\n",
      "Epoch [9/20], Step [3000/12500], Loss: 0.9860\n",
      "Epoch [9/20], Step [4000/12500], Loss: 1.7866\n",
      "Epoch [9/20], Step [5000/12500], Loss: 2.2072\n",
      "Epoch [9/20], Step [6000/12500], Loss: 0.9266\n",
      "Epoch [9/20], Step [7000/12500], Loss: 1.5748\n",
      "Epoch [9/20], Step [8000/12500], Loss: 0.9196\n",
      "Epoch [9/20], Step [9000/12500], Loss: 1.2292\n",
      "Epoch [9/20], Step [10000/12500], Loss: 0.3089\n",
      "Epoch [9/20], Step [11000/12500], Loss: 0.3071\n",
      "Epoch [9/20], Step [12000/12500], Loss: 0.9573\n",
      "Epoch [10/20], Step [1000/12500], Loss: 1.3164\n",
      "Epoch [10/20], Step [2000/12500], Loss: 0.3194\n",
      "Epoch [10/20], Step [3000/12500], Loss: 0.4445\n",
      "Epoch [10/20], Step [4000/12500], Loss: 0.3826\n",
      "Epoch [10/20], Step [5000/12500], Loss: 1.9326\n",
      "Epoch [10/20], Step [6000/12500], Loss: 1.1065\n",
      "Epoch [10/20], Step [7000/12500], Loss: 1.6190\n",
      "Epoch [10/20], Step [8000/12500], Loss: 0.5244\n",
      "Epoch [10/20], Step [9000/12500], Loss: 0.4234\n",
      "Epoch [10/20], Step [10000/12500], Loss: 0.2656\n",
      "Epoch [10/20], Step [11000/12500], Loss: 1.6059\n",
      "Epoch [10/20], Step [12000/12500], Loss: 1.1201\n",
      "Epoch [11/20], Step [1000/12500], Loss: 0.0319\n",
      "Epoch [11/20], Step [2000/12500], Loss: 0.9902\n",
      "Epoch [11/20], Step [3000/12500], Loss: 0.3408\n",
      "Epoch [11/20], Step [4000/12500], Loss: 0.6755\n",
      "Epoch [11/20], Step [5000/12500], Loss: 0.2230\n",
      "Epoch [11/20], Step [6000/12500], Loss: 1.3305\n",
      "Epoch [11/20], Step [7000/12500], Loss: 1.8143\n",
      "Epoch [11/20], Step [8000/12500], Loss: 0.9271\n",
      "Epoch [11/20], Step [9000/12500], Loss: 0.4063\n",
      "Epoch [11/20], Step [10000/12500], Loss: 0.4198\n",
      "Epoch [11/20], Step [11000/12500], Loss: 0.8859\n",
      "Epoch [11/20], Step [12000/12500], Loss: 0.5972\n",
      "Epoch [12/20], Step [1000/12500], Loss: 1.4421\n",
      "Epoch [12/20], Step [2000/12500], Loss: 1.5351\n",
      "Epoch [12/20], Step [3000/12500], Loss: 0.5689\n",
      "Epoch [12/20], Step [4000/12500], Loss: 1.6065\n",
      "Epoch [12/20], Step [5000/12500], Loss: 1.9412\n",
      "Epoch [12/20], Step [6000/12500], Loss: 0.7240\n",
      "Epoch [12/20], Step [7000/12500], Loss: 0.5614\n",
      "Epoch [12/20], Step [8000/12500], Loss: 1.9560\n",
      "Epoch [12/20], Step [9000/12500], Loss: 0.2258\n",
      "Epoch [12/20], Step [10000/12500], Loss: 0.2309\n",
      "Epoch [12/20], Step [11000/12500], Loss: 1.3757\n",
      "Epoch [12/20], Step [12000/12500], Loss: 0.6700\n",
      "Epoch [13/20], Step [1000/12500], Loss: 2.7378\n",
      "Epoch [13/20], Step [2000/12500], Loss: 0.6396\n",
      "Epoch [13/20], Step [3000/12500], Loss: 0.4602\n",
      "Epoch [13/20], Step [4000/12500], Loss: 2.9027\n",
      "Epoch [13/20], Step [5000/12500], Loss: 1.0193\n",
      "Epoch [13/20], Step [6000/12500], Loss: 0.3682\n",
      "Epoch [13/20], Step [7000/12500], Loss: 0.2343\n",
      "Epoch [13/20], Step [8000/12500], Loss: 0.9511\n",
      "Epoch [13/20], Step [9000/12500], Loss: 1.5619\n",
      "Epoch [13/20], Step [10000/12500], Loss: 1.3247\n",
      "Epoch [13/20], Step [11000/12500], Loss: 1.8203\n",
      "Epoch [13/20], Step [12000/12500], Loss: 1.4237\n",
      "Epoch [14/20], Step [1000/12500], Loss: 1.6358\n",
      "Epoch [14/20], Step [2000/12500], Loss: 1.7499\n",
      "Epoch [14/20], Step [3000/12500], Loss: 0.8604\n",
      "Epoch [14/20], Step [4000/12500], Loss: 1.9194\n",
      "Epoch [14/20], Step [5000/12500], Loss: 1.2643\n",
      "Epoch [14/20], Step [6000/12500], Loss: 0.4698\n",
      "Epoch [14/20], Step [7000/12500], Loss: 0.8215\n",
      "Epoch [14/20], Step [8000/12500], Loss: 1.0586\n",
      "Epoch [14/20], Step [9000/12500], Loss: 0.8130\n",
      "Epoch [14/20], Step [10000/12500], Loss: 0.8387\n",
      "Epoch [14/20], Step [11000/12500], Loss: 0.2404\n",
      "Epoch [14/20], Step [12000/12500], Loss: 0.1352\n",
      "Epoch [15/20], Step [1000/12500], Loss: 0.5824\n",
      "Epoch [15/20], Step [2000/12500], Loss: 0.9669\n",
      "Epoch [15/20], Step [3000/12500], Loss: 1.1126\n",
      "Epoch [15/20], Step [4000/12500], Loss: 2.1950\n",
      "Epoch [15/20], Step [5000/12500], Loss: 0.5836\n",
      "Epoch [15/20], Step [6000/12500], Loss: 0.6421\n",
      "Epoch [15/20], Step [7000/12500], Loss: 1.4292\n",
      "Epoch [15/20], Step [8000/12500], Loss: 0.5749\n",
      "Epoch [15/20], Step [9000/12500], Loss: 0.5919\n",
      "Epoch [15/20], Step [10000/12500], Loss: 0.2561\n",
      "Epoch [15/20], Step [11000/12500], Loss: 2.2530\n",
      "Epoch [15/20], Step [12000/12500], Loss: 1.2539\n",
      "Epoch [16/20], Step [1000/12500], Loss: 1.1059\n",
      "Epoch [16/20], Step [2000/12500], Loss: 1.0050\n",
      "Epoch [16/20], Step [3000/12500], Loss: 0.8896\n",
      "Epoch [16/20], Step [4000/12500], Loss: 2.0197\n",
      "Epoch [16/20], Step [5000/12500], Loss: 1.4290\n",
      "Epoch [16/20], Step [6000/12500], Loss: 0.5225\n",
      "Epoch [16/20], Step [7000/12500], Loss: 0.5998\n",
      "Epoch [16/20], Step [8000/12500], Loss: 1.5307\n",
      "Epoch [16/20], Step [9000/12500], Loss: 1.8357\n",
      "Epoch [16/20], Step [10000/12500], Loss: 0.8474\n",
      "Epoch [16/20], Step [11000/12500], Loss: 0.9328\n",
      "Epoch [16/20], Step [12000/12500], Loss: 1.1696\n",
      "Epoch [17/20], Step [1000/12500], Loss: 0.4583\n",
      "Epoch [17/20], Step [2000/12500], Loss: 0.9703\n",
      "Epoch [17/20], Step [3000/12500], Loss: 0.3774\n",
      "Epoch [17/20], Step [4000/12500], Loss: 0.0319\n",
      "Epoch [17/20], Step [5000/12500], Loss: 1.8292\n",
      "Epoch [17/20], Step [6000/12500], Loss: 1.0219\n",
      "Epoch [17/20], Step [7000/12500], Loss: 0.3562\n",
      "Epoch [17/20], Step [8000/12500], Loss: 0.9713\n",
      "Epoch [17/20], Step [9000/12500], Loss: 0.5860\n",
      "Epoch [17/20], Step [10000/12500], Loss: 1.0160\n",
      "Epoch [17/20], Step [11000/12500], Loss: 0.1696\n",
      "Epoch [17/20], Step [12000/12500], Loss: 0.4816\n",
      "Epoch [18/20], Step [1000/12500], Loss: 0.9177\n",
      "Epoch [18/20], Step [2000/12500], Loss: 0.9477\n",
      "Epoch [18/20], Step [3000/12500], Loss: 0.6068\n",
      "Epoch [18/20], Step [4000/12500], Loss: 0.7846\n",
      "Epoch [18/20], Step [5000/12500], Loss: 0.7998\n",
      "Epoch [18/20], Step [6000/12500], Loss: 1.9575\n",
      "Epoch [18/20], Step [7000/12500], Loss: 1.2551\n",
      "Epoch [18/20], Step [8000/12500], Loss: 0.8784\n",
      "Epoch [18/20], Step [9000/12500], Loss: 0.8401\n",
      "Epoch [18/20], Step [10000/12500], Loss: 0.4793\n",
      "Epoch [18/20], Step [11000/12500], Loss: 0.8405\n",
      "Epoch [18/20], Step [12000/12500], Loss: 0.5625\n",
      "Epoch [19/20], Step [1000/12500], Loss: 0.0756\n",
      "Epoch [19/20], Step [2000/12500], Loss: 1.7817\n",
      "Epoch [19/20], Step [3000/12500], Loss: 0.2925\n",
      "Epoch [19/20], Step [4000/12500], Loss: 1.2689\n",
      "Epoch [19/20], Step [5000/12500], Loss: 0.8459\n",
      "Epoch [19/20], Step [6000/12500], Loss: 1.3496\n",
      "Epoch [19/20], Step [7000/12500], Loss: 0.6293\n",
      "Epoch [19/20], Step [8000/12500], Loss: 1.8331\n",
      "Epoch [19/20], Step [9000/12500], Loss: 0.3902\n",
      "Epoch [19/20], Step [10000/12500], Loss: 1.4555\n",
      "Epoch [19/20], Step [11000/12500], Loss: 0.2854\n",
      "Epoch [19/20], Step [12000/12500], Loss: 1.1787\n",
      "Epoch [20/20], Step [1000/12500], Loss: 0.0613\n",
      "Epoch [20/20], Step [2000/12500], Loss: 0.1034\n",
      "Epoch [20/20], Step [3000/12500], Loss: 0.3013\n",
      "Epoch [20/20], Step [4000/12500], Loss: 1.0333\n",
      "Epoch [20/20], Step [5000/12500], Loss: 0.3454\n",
      "Epoch [20/20], Step [6000/12500], Loss: 0.1080\n",
      "Epoch [20/20], Step [7000/12500], Loss: 1.2627\n",
      "Epoch [20/20], Step [8000/12500], Loss: 0.3852\n",
      "Epoch [20/20], Step [9000/12500], Loss: 1.2184\n",
      "Epoch [20/20], Step [10000/12500], Loss: 0.9804\n",
      "Epoch [20/20], Step [11000/12500], Loss: 2.2691\n",
      "Epoch [20/20], Step [12000/12500], Loss: 1.8331\n"
     ]
    }
   ],
   "source": [
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # original shape: [batch_size, 3, 32, 32] = [batch_size, 3, 1024]\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 1000 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e5159e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 59.65\n",
      "Accuracy of plane : 68.7 %\n",
      "Accuracy of car : 64.8 %\n",
      "Accuracy of bird : 53.8 %\n",
      "Accuracy of cat : 54.4 %\n",
      "Accuracy of deer : 48.1 %\n",
      "Accuracy of dog : 35.0 %\n",
      "Accuracy of frog : 67.0 %\n",
      "Accuracy of horse : 54.3 %\n",
      "Accuracy of ship : 76.4 %\n",
      "Accuracy of truck : 74.0 %\n",
      "Precision: 0.6204\n",
      "Recall:    0.5965\n",
      "F1-score:  0.5987\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       plane       0.61      0.69      0.65      1000\n",
      "         car       0.81      0.65      0.72      1000\n",
      "        bird       0.42      0.54      0.47      1000\n",
      "         cat       0.37      0.54      0.44      1000\n",
      "        deer       0.56      0.48      0.52      1000\n",
      "         dog       0.60      0.35      0.44      1000\n",
      "        frog       0.69      0.67      0.68      1000\n",
      "       horse       0.78      0.54      0.64      1000\n",
      "        ship       0.72      0.76      0.74      1000\n",
      "       truck       0.64      0.74      0.68      1000\n",
      "\n",
      "    accuracy                           0.60     10000\n",
      "   macro avg       0.62      0.60      0.60     10000\n",
      "weighted avg       0.62      0.60      0.60     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for images, labels in test_loader:\n",
    "        # images = images.to(device)\n",
    "        # labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(predicted.numpy())\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if label == pred:\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "    \n",
    "    \n",
    "acc = 100.0 * n_correct / n_samples\n",
    "print(f'Accuracy of the network on the 10000 test images: {acc}')\n",
    "\n",
    "for i in range(10):\n",
    "    acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "    print(f'Accuracy of {classes[i]} : {acc} %')\n",
    "    \n",
    "precision = precision_score(y_true, y_pred, average='macro')\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-score:  {f1:.4f}\")\n",
    "\n",
    "# Classification report chi tiết từng lớp\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.7",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
